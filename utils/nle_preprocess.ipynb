{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQA-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "imgid2name = json.load(open('nle_data/coco_id2name.json', 'r'))\n",
    "\n",
    "ques_list = json.load(open('nle_data/v2_OpenEnded_mscoco_train2014_questions.json', 'r'))['questions'] + \\\n",
    "            json.load(open('nle_data/v2_OpenEnded_mscoco_val2014_questions.json', 'r'))['questions']\n",
    "\n",
    "ans_list  = json.load(open('nle_data/v2_mscoco_train2014_annotations.json', 'r'))['annotations'] + \\\n",
    "            json.load(open('nle_data/v2_mscoco_val2014_annotations.json', 'r'))['annotations']\n",
    "\n",
    "exp_train = json.load(open('nle_data/VQA-X/textual/train_exp_anno.json', 'r'))\n",
    "id2question = {str(q['question_id']): q['question'] for q in ques_list}\n",
    "id2data = {}\n",
    "\n",
    "for item in ans_list:\n",
    "    \n",
    "    qid = str(item['question_id'])\n",
    "    \n",
    "    if str(qid) not in exp_train.keys():\n",
    "        continue\n",
    "    \n",
    "    id2data[qid] = {}\n",
    "    id2data[qid]['question'] = id2question[qid]\n",
    "    id2data[qid]['answers'] = item['answers']\n",
    "    id2data[qid]['image_id'] = str(item['image_id'])\n",
    "    id2data[qid]['image_name'] = imgid2name[str(item['image_id'])]\n",
    "    exps = exp_train[str(qid)]\n",
    "    id2data[qid]['explanation'] = [exps[i].lower().replace(\".\", \"\") for i in range(len(exps))]\n",
    "    \n",
    "with open('nle_data/VQA-X/vqaX_train.json', 'w') as w:\n",
    "    json.dump(id2data, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACT-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "exp_train = json.load(open('nle_data/ACT-X/textual/exp_train_split.json'))\n",
    "id2data = {}\n",
    "\n",
    "for key,value in exp_train.items():\n",
    "\n",
    "    id2data[key] = {}\n",
    "    id2data[key]['answers'] = value['ans'].split(\",\")[0]\n",
    "    id2data[key]['image_id'] = value['iid']\n",
    "    id2data[key]['image_name'] = value['iid'] + '.jpg'\n",
    "    id2data[key]['explanation'] = [value['exp'][i].lower().replace(\".\", \"\") for i in range(len(value['exp']))]\n",
    "    \n",
    "with open('nle_data/ACT-X/actX_train.json', 'w') as w:\n",
    "    json.dump(id2data, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eSNLI-VE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "exp_train = pd.read_csv('nle_data/eSNLI-VE/esnlive_train.csv').to_dict('records')\n",
    "\n",
    "id2data = {}\n",
    "for i,item in enumerate(exp_train):\n",
    "    \n",
    "    key = item['Unnamed: 0']\n",
    "    id2data[key] = {}\n",
    "    id2data[key]['hypothesis'] = item['hypothesis']\n",
    "    id2data[key]['answers'] = item['gold_label']\n",
    "    id2data[key]['image_name'] = item['Flickr30kID'] \n",
    "    id2data[key]['explanation'] = item['explanation'].lower().replace(\".\", \"\")\n",
    "    \n",
    "with open('nle_data/eSNLI-VE/esnlive_train.json', 'w') as w:\n",
    "    json.dump(id2data, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines as jsnl\n",
    "import json\n",
    "\n",
    "annotFolder = 'annotVCR/'\n",
    "images_folder = 'images/vcr1images/'\n",
    "\n",
    "def replace(x):\n",
    "    if type(x) == list:\n",
    "        names = \" and \".join([objects[x[i]] + str(x[i]) for i in range(len(x))])\n",
    "        return names\n",
    "    return x\n",
    "\n",
    "\n",
    "train_ann = jsnl.Reader(open(annotFolder + 'train.jsonl'))\n",
    "data = [t for t in train_ann.iter()]\n",
    "splits = json.load(open(annotFolder + 'vcr_splits.json', 'r'))\n",
    "current_split = splits['train']\n",
    "id2data = {}\n",
    "\n",
    "for item in data:\n",
    "         \n",
    "    annID = item['annot_id']\n",
    "\n",
    "    if annID not in current_split:\n",
    "        continue\n",
    "    \n",
    "    ID = annID.split(\"-\")[-1]\n",
    "    metd = json.load(open(str(images_folder + item['metadata_fn'])))\n",
    "    img_name = item['img_fn']\n",
    "    objects = item['objects']\n",
    "    question = item['question'][:-1]\n",
    "    answer = item['answer_choices'][item['answer_label']][:-1]\n",
    "    explanation = item['rationale_choices'][item['rationale_label']][:-1]\n",
    "    boxes_data = metd['boxes']\n",
    "    image_w, image_h = metd['width'], metd['height']\n",
    "\n",
    "    str_question = \" \".join(list(map(replace, question))).lower()\n",
    "    str_answer =  \" \".join(list(map(replace, answer))).lower()\n",
    "    str_explanation =  \" \".join(list(map(replace, explanation))).lower()\n",
    "    \n",
    "    id2data[ID] = {}\n",
    "    id2data[ID]['question'] = str_question\n",
    "    id2data[ID]['answers'] = str_answer\n",
    "    id2data[ID]['explanation'] = str_explanation\n",
    "    id2data[ID]['annot_id'] = annID\n",
    "    id2data[ID]['img_name'] = img_name\n",
    "    id2data[ID]['boxes_data'] = boxes_data\n",
    "    id2data[ID]['image_w'] = image_w\n",
    "    id2data[ID]['image_h'] = image_h\n",
    "    id2data[ID]['objects'] = objects\n",
    "    \n",
    "assert len(id2data) == len(current_split)\n",
    "with open('vcr_train.json', 'w') as w:\n",
    "    json.dump(id2data, w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
